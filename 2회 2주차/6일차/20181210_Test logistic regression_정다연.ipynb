{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "#GD를 활용한 LogisticRegression\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, threshold=0.01, max_iterations=100000, fit_intercept=True, verbose=False):\n",
    "        self._learning_rate = learning_rate  # 학습 계수\n",
    "        self._max_iterations = max_iterations  # 반복 횟수\n",
    "        self._threshold = threshold  # 학습 중단 계수\n",
    "        self._fit_intercept = fit_intercept  # 절편 사용 여부를 결정\n",
    "        self._verbose = verbose  # 중간 진행사항 출력 여부\n",
    "\n",
    "    # theta(W) 계수들 return\n",
    "    def get_coeff(self):\n",
    "        return self._W\n",
    "\n",
    "    # 절편 추가\n",
    "    def add_intercept(self, x_data):\n",
    "        intercept = np.ones((x_data.shape[0], 1))\n",
    "        return np.concatenate((intercept, x_data), axis=1)\n",
    "\n",
    "    # 시그모이드 함수(로지스틱 함수)\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    # h: hypothesis, y: y_data_train\n",
    "    # 사건 1이 일어날 확률과 사건 1이 일어나지 않을 확률을 \n",
    "    def cost(self, h, y):##어떤뜻인지 파악하기(cost function에 대한 이해필요(GD,SGD 찾아보기))\n",
    "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "\n",
    "    \n",
    "    def fit(self, x_data, y_data):\n",
    "        num_examples, num_features = np.shape(x_data)\n",
    "\n",
    "        if self._fit_intercept:\n",
    "            x_data = self.add_intercept(x_data)\n",
    "\n",
    "        \n",
    "        self._W = np.zeros(x_data.shape[1])\n",
    "\n",
    "        for i in range(self._max_iterations):\n",
    "            z = np.dot(x_data, self._W)\n",
    "            hypothesis = self.sigmoid(z)\n",
    "       \n",
    "            \n",
    "\n",
    "            #실제값과 예측값의 차이\n",
    "            diff = hypothesis - y_data\n",
    "\n",
    "            cost = self.cost(hypothesis, y_data)\n",
    "\n",
    "            ##어떤 과정인지 설명하기\n",
    "            # 내적(x_data^T 한 것과 diff를) 그리고 그 값을 훈련샘플 수 만큼 나누기.\n",
    "            # = cost function의 편미분을 의미함.\n",
    "            gradient = np.dot(x_data.transpose(), diff) / num_examples\n",
    "            \n",
    "            \n",
    "            self._W -= self._learning_rate * gradient\n",
    "\n",
    "           \n",
    "            if cost < self._threshold:\n",
    "                return False\n",
    "\n",
    "           \n",
    "            if (self._verbose == True and i % 100 == 0):\n",
    "                print('cost :', cost)\n",
    "\n",
    "    def predict_prob(self, x_data):\n",
    "        if self._fit_intercept:\n",
    "            x_data = self.add_intercept(x_data)\n",
    "\n",
    "        return self.sigmoid(np.dot(x_data, self._W))\n",
    "\n",
    "    def predict(self, x_data):\n",
    "        \n",
    "        return self.predict_prob(x_data).round()##왜 라운드 함수를 쓰는지 : round가 반올림 함수라면, 0 아니면 1로 나누기 위해서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Social_Network_Ads.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User ID             int64\n",
       "Gender             object\n",
       "Age                 int64\n",
       "EstimatedSalary     int64\n",
       "Purchased           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID            int64\n",
      "Gender             int64\n",
      "Age                int64\n",
      "EstimatedSalary    int64\n",
      "Purchased          int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510       1   19            19000          0\n",
       "1  15810944       1   35            20000          0\n",
       "2  15668575       2   26            43000          0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'] = df.Gender.map({'Male':1, 'Female':2})\n",
    "print(df.dtypes)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test 나누기 방법1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_Y = MinMaxScaler()\n",
    "\n",
    "\n",
    "x_data_train = (df.iloc[:int(len(df)*0.8),1:4])\n",
    "#x_data_train = np.array(x_data_train)\n",
    "scaler_X.fit(x_data_train)\n",
    "x_data_train = pd.DataFrame(scaler_X.transform(x_data_train), index=x_data_train.index, columns=x_data_train.columns)\n",
    "\n",
    "y_data_train = df.iloc[:int(len(df)*0.8),4]\n",
    "#scaler_Y.fit_transform(y_data_train)\n",
    "#y_data_train = np.array(y_data_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_data_test = df.iloc[int(len(df)*0.8):, 1:4]\n",
    "#x_data_test = np.array(x_data_test)\n",
    "scaler_X.fit(x_data_test)\n",
    "x_data_test = pd.DataFrame(scaler_X.transform(x_data_test), index=x_data_test.index, columns=x_data_test.columns)\n",
    "\n",
    "y_data_test = df.iloc[int(len(df)*0.8):, 4]\n",
    "#y_data_test = np.array(y_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test 나누기 방법2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X=df.iloc[:,1:4]\n",
    "y=df.iloc[:,4]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_Y = MinMaxScaler()\n",
    "\n",
    "scaler_X.fit(X_train)\n",
    "X_train = pd.DataFrame(scaler_X.transform(X_train), index=X_train.index, columns=X_train.columns)\n",
    "\n",
    "scaler_X.fit(X_test)\n",
    "X_test = pd.DataFrame(scaler_X.transform(X_test), index=X_test.index, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression(learning_rate=0.5, max_iterations=10000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost : 0.6931471805599467\n",
      "cost : 0.4633566700481224\n",
      "cost : 0.40396606829909104\n",
      "cost : 0.37650664424866365\n",
      "cost : 0.3614334055318898\n",
      "cost : 0.35223733131945195\n",
      "cost : 0.34622349037678307\n",
      "cost : 0.34209513989286167\n",
      "cost : 0.3391584567440826\n",
      "cost : 0.33701210521213887\n",
      "cost : 0.33540974350736136\n",
      "cost : 0.3341929729936327\n",
      "cost : 0.33325607710110267\n",
      "cost : 0.33252631956994894\n",
      "cost : 0.33195237583622694\n",
      "cost : 0.33149725303332944\n",
      "cost : 0.3311338027348283\n",
      "cost : 0.3308417905331231\n",
      "cost : 0.33060593215054135\n",
      "cost : 0.3304145472621572\n",
      "cost : 0.3302586182669557\n",
      "cost : 0.3301311205594506\n",
      "cost : 0.3300265385039335\n",
      "cost : 0.3299405107167562\n",
      "cost : 0.3298695668457842\n",
      "cost : 0.329810930037923\n",
      "cost : 0.3297623671893944\n",
      "cost : 0.329722074371794\n",
      "cost : 0.3296885884367787\n",
      "cost : 0.32966071829843513\n",
      "cost : 0.3296374911423109\n",
      "cost : 0.32961811005234753\n",
      "cost : 0.32960192043921605\n",
      "cost : 0.3295883833013611\n",
      "cost : 0.3295770538251343\n",
      "cost : 0.3295675641820875\n",
      "cost : 0.3295596096440886\n",
      "cost : 0.329552937334655\n",
      "cost : 0.3295473370848462\n",
      "cost : 0.3295426339766633\n",
      "cost : 0.3295386822450252\n",
      "cost : 0.329535360277607\n",
      "cost : 0.32953256650491963\n",
      "cost : 0.32953021601459637\n",
      "cost : 0.32952823775654505\n",
      "cost : 0.32952657223150567\n",
      "cost : 0.3295251695760821\n",
      "cost : 0.32952398797372073\n",
      "cost : 0.3295229923342187\n",
      "cost : 0.3295221531949092\n",
      "cost : 0.3295214458051739\n",
      "cost : 0.329520849362834\n",
      "cost : 0.3295203463765452\n",
      "cost : 0.32951992213290515\n",
      "cost : 0.32951956425067336\n",
      "cost : 0.3295192623075624\n",
      "cost : 0.3295190075275537\n",
      "cost : 0.32951879251873806\n",
      "cost : 0.32951861105338576\n",
      "cost : 0.32951845788332534\n",
      "cost : 0.32951832858488983\n",
      "cost : 0.32951821942862425\n",
      "cost : 0.3295181272697556\n",
      "cost : 0.32951804945607244\n",
      "cost : 0.3295179837504246\n",
      "cost : 0.32951792826549386\n",
      "cost : 0.3295178814088767\n",
      "cost : 0.3295178418368375\n",
      "cost : 0.32951780841534895\n",
      "cost : 0.3295177801872652\n",
      "cost : 0.32951775634465735\n",
      "cost : 0.3295177362054892\n",
      "cost : 0.32951771919395617\n",
      "cost : 0.32951770482390297\n",
      "cost : 0.3295176926848379\n",
      "cost : 0.32951768243013396\n",
      "cost : 0.3295176737670798\n",
      "cost : 0.3295176664484753\n",
      "cost : 0.3295176602655495\n",
      "cost : 0.3295176550419778\n",
      "cost : 0.3295176506288314\n",
      "cost : 0.3295176469003179\n",
      "cost : 0.3295176437501826\n",
      "cost : 0.32951764108867143\n",
      "cost : 0.32951763883996665\n",
      "cost : 0.32951763694002045\n",
      "cost : 0.3295176353347266\n",
      "cost : 0.32951763397837625\n",
      "cost : 0.3295176328323555\n",
      "cost : 0.3295176318640393\n",
      "cost : 0.32951763104586795\n",
      "cost : 0.32951763035455506\n",
      "cost : 0.3295176297704281\n",
      "cost : 0.32951762927686506\n",
      "cost : 0.32951762885982283\n",
      "cost : 0.3295176285074361\n",
      "cost : 0.3295176282096798\n",
      "cost : 0.32951762795808415\n",
      "cost : 0.3295176277454909\n",
      "cost : 0.32951762756585434\n"
     ]
    }
   ],
   "source": [
    "lr.fit(x_data_train, y_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost : 0.6931471805599467\n",
      "cost : 0.51296747678464\n",
      "cost : 0.453257809790976\n",
      "cost : 0.4245025446263518\n",
      "cost : 0.40828052497324857\n",
      "cost : 0.3981739726224388\n",
      "cost : 0.39144609649976775\n",
      "cost : 0.38675257063793306\n",
      "cost : 0.38336278957509606\n",
      "cost : 0.380848720361131\n",
      "cost : 0.37894471034833654\n",
      "cost : 0.37747821221410943\n",
      "cost : 0.3763329640351631\n",
      "cost : 0.3754282321638834\n",
      "cost : 0.37470652769751184\n",
      "cost : 0.3741260360373769\n",
      "cost : 0.37365578751070183\n",
      "cost : 0.3732724840421635\n",
      "cost : 0.3729583597947435\n",
      "cost : 0.3726997061475761\n",
      "cost : 0.37248583440641087\n",
      "cost : 0.37230833344164493\n",
      "cost : 0.3721605300261309\n",
      "cost : 0.3720370909896098\n",
      "cost : 0.3719337261984349\n",
      "cost : 0.371846964265927\n",
      "cost : 0.37177398142384055\n",
      "cost : 0.3717124697210907\n",
      "cost : 0.37166053463762194\n",
      "cost : 0.3716166149226762\n",
      "cost : 0.3715794193810726\n",
      "cost : 0.37154787669477696\n",
      "cost : 0.37152109534982636\n",
      "cost : 0.37149833145464806\n",
      "cost : 0.37147896276269116\n",
      "cost : 0.3714624676036665\n",
      "cost : 0.3714484077209733\n",
      "cost : 0.37143641423447626\n",
      "cost : 0.3714261761165101\n",
      "cost : 0.3714174306983682\n",
      "cost : 0.371409955824441\n",
      "cost : 0.37140356334879\n",
      "cost : 0.37139809372963806\n",
      "cost : 0.3713934115249725\n",
      "cost : 0.3713894016301783\n",
      "cost : 0.37138596612857316\n",
      "cost : 0.37138302164964865\n",
      "cost : 0.3713804971489965\n",
      "cost : 0.3713783320393483\n",
      "cost : 0.37137647461464934\n",
      "cost : 0.3713748807192153\n",
      "cost : 0.3713735126222972\n",
      "cost : 0.37137233806511316\n",
      "cost : 0.37137132945294277\n",
      "cost : 0.3713704631694491\n",
      "cost : 0.37136971899412113\n",
      "cost : 0.3713690796068628\n",
      "cost : 0.37136853016630966\n",
      "cost : 0.37136805795060546\n",
      "cost : 0.3713676520511537\n",
      "cost : 0.37136730311134414\n",
      "cost : 0.3713670031035004\n",
      "cost : 0.371366745138341\n",
      "cost : 0.3713665233021258\n",
      "cost : 0.37136633251738627\n",
      "cost : 0.3713661684237636\n",
      "cost : 0.37136602727601614\n",
      "cost : 0.3713659058566719\n",
      "cost : 0.3713658014012038\n",
      "cost : 0.3713657115339018\n",
      "cost : 0.3713656342129016\n",
      "cost : 0.3713655676830386\n",
      "cost : 0.37136551043541166\n",
      "cost : 0.3713654611726825\n",
      "cost : 0.3713654187792964\n",
      "cost : 0.3713653822959181\n",
      "cost : 0.37136535089748113\n",
      "cost : 0.371365323874336\n",
      "cost : 0.37136530061605744\n",
      "cost : 0.37136528059753465\n",
      "cost : 0.37136526336701503\n",
      "cost : 0.3713652485358344\n",
      "cost : 0.371365235769586\n",
      "cost : 0.371365224780531\n",
      "cost : 0.3713652153210747\n",
      "cost : 0.3713652071781549\n",
      "cost : 0.3713652001684181\n",
      "cost : 0.3713651941340707\n",
      "cost : 0.37136518893931203\n",
      "cost : 0.3713651844672636\n",
      "cost : 0.3713651806173301\n",
      "cost : 0.3713651773029281\n",
      "cost : 0.3713651744495334\n",
      "cost : 0.3713651719929974\n",
      "cost : 0.3713651698781041\n",
      "cost : 0.37136516805732306\n",
      "cost : 0.3713651664897403\n",
      "cost : 0.3713651651401352\n",
      "cost : 0.37136516397818986\n",
      "cost : 0.3713651629778033\n"
     ]
    }
   ],
   "source": [
    "lr_2=LogisticRegression(learning_rate=0.5, max_iterations=10000, verbose=True)\n",
    "lr_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=lr.predict(x_data_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_2=lr_2.predict(X_test)\n",
    "preds_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(list(y_data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "앞 80% 분량을 train data로, 나머지 뒤 20% 분량을 test data로 지정하고 시행시 정확도 :  0.6625\n"
     ]
    }
   ],
   "source": [
    "print('앞 80% 분량을 train data로, 나머지 뒤 20% 분량을 test data로 지정하고 시행시 정확도 : ', (preds == y_data_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random으로 train/test dataset 분류시 정확도 :  0.8875\n"
     ]
    }
   ],
   "source": [
    "print('random으로 train/test dataset 분류시 정확도 : ', (preds_2 == y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost : 0.6931471805599454\n",
      "cost : 0.05794011269381071\n",
      "cost : 0.03120070412962307\n",
      "cost : 0.02166715205967918\n",
      "cost : 0.01672282428356398\n",
      "cost : 0.013678670257084902\n",
      "cost : 0.011607922362094413\n",
      "cost : 0.010104037475698113\n",
      "1.0\n",
      "[-0.3140981  -0.49604387 -1.66996011  2.62273613  1.19189337]\n"
     ]
    }
   ],
   "source": [
    "# iris dataset 활용 예제.\n",
    "# 출처: https://github.com/yoonkt200/ml-theory-python/blob/master/01-regression/logistic-regression/logistic-regression.py\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data[:, :]\n",
    "\n",
    "y = (iris.target != 0) * 1\n",
    "\n",
    "\n",
    "\n",
    "# 학습 implementation\n",
    "\n",
    "model = LogisticRegression(learning_rate=0.1, threshold=0.01, max_iterations=10000, verbose=True)\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "preds = model.predict(X)\n",
    "\n",
    "print((preds == y).mean())\n",
    "\n",
    "print(model.get_coeff())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
